{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Import Statements \n",
    "import wikipedia\n",
    "import textacy.corpus\n",
    "import re\n",
    "from textacy.extract import named_entities\n",
    "import textacy.keyterms\n",
    "import textacy.preprocess\n",
    "import textacy.spacy_utils\n",
    "from textacy.datasets.wikipedia import strip_markup\n",
    "from py2neo import Node, Relationship, Graph, NodeSelector, NodeSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_section_headers = re.compile('==(.*?)==')\n",
    "re_whitespace = re.compile('\\\\n{1,}\\s*')\n",
    "re_display_styles = re.compile('(\\{)(.*?\\}){0,4}')\n",
    "re_duplicate_spaces = re.compile('(\\s{2,})')\n",
    "re_escaped_elements = re.compile(r'(\\\\)(\\w)*')\n",
    "re_newlines = re.compile('(\\\\n)')\n",
    "re_not_words = re.compile('(\\ )(\\W){1,2}(\\ )')\n",
    "re_cruft = re.compile('[^(A-Z|a-z|\\.|\\,|\\ |\\\"|\\?)]')\n",
    "re_single_words = re.compile('(\\ )(\\w){1,2}(\\ )')\n",
    "re_apostrophes = re.compile(\"\\\\'\")\n",
    "re_rename_1 = re.compile('[^(A-Z|a-z|\\.|\\,|\\ |\\\"|\\?)]')\n",
    "re_rename_2 = re.compile('[\\||\\(|\\)]')\n",
    "re_rename_3 = re.compile('(\\ )(\\W)*(\\ )')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def create_indexes(graph): \n",
    "    graph.run('CREATE INDEX ON :Category(catId)')\n",
    "    graph.run('CREATE INDEX ON :Category(catName)')\n",
    "    graph.run('CREATE INDEX ON :Page(pageTitle)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def create_root(graph, category_name): \n",
    "    graph.run('CREATE (c:Category:RootCategory {{catId:0, catName: \"{0!s}\", subcatsFetched: false, pagesFetched: false, level: 0}})'.format(category_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def fetch_categories(graph, levels=3): \n",
    "    graph.run('''\n",
    "              UNWIND range(0, {0}) as level \\n\n",
    "              CALL apoc.cypher.doIt(\" \\n\n",
    "              MATCH (c:Category {{subcatsFetched: false, level: $level}}) \\n\n",
    "              CALL apoc.load.json('https://en.wikipedia.org/w/api.php?format=json&action=query&list=categorymembers&cmtype=subcat&cmtitle=Category:' + apoc.text.urlencode(c.catName) + '&cmprop=ids%7Ctitle&cmlimit=500') \\n\n",
    "              YIELD value as results \\n\n",
    "              UNWIND results.query.categorymembers AS subcat \\n\n",
    "              MERGE (sc:Category {{catId: subcat.pageid}}) \\n\n",
    "              ON CREATE SET sc.catName = substring(subcat.title, 9), \\n\n",
    "              sc.subcatsFetched = false, \\n\n",
    "              sc.pagesFetched = false, \\n\n",
    "              sc.level = $level + 1 \\n\n",
    "              WITH sc,c \\n\n",
    "              CALL apoc.create.addLabels(sc,['Level' +  ($level + 1) + 'Category']) YIELD node \\n\n",
    "              MERGE (sc)-[:SUBCAT_OF]->(c) \\n\n",
    "              WITH DISTINCT c \\n\n",
    "              SET c.subcatsFetched = true\", {{ level: level }}) YIELD value \\n\n",
    "              RETURN value\n",
    "              '''.format(levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def fetch_pages(graph, levels=3): \n",
    "    graph.run('''\n",
    "              UNWIND range(0, {0}) as level \\n\n",
    "              CALL apoc.cypher.doIt(\" \\n\n",
    "              MATCH (c:Category {{ pagesFetched: false, level: $level }}) \\n\n",
    "              CALL apoc.load.json('https://en.wikipedia.org/w/api.php?format=json&action=query&list=categorymembers&cmtype=page&cmtitle=Category:' + apoc.text.urlencode(c.catName) + '&cmprop=ids%7Ctitle&cmlimit=500') \\n\n",
    "              YIELD value as results \\n\n",
    "              UNWIND results.query.categorymembers AS page \\n\n",
    "              MERGE (p:Page {{pageId: page.pageid}}) \\n\n",
    "              ON CREATE SET p.pageTitle = page.title, p.pageUrl = 'http://en.wikipedia.org/wiki/' + apoc.text.urlencode(replace(page.title, ' ', '_')) \\n\n",
    "              WITH p,c \\n\n",
    "              MERGE (p)-[:IN_CATEGORY]->(c) \\n\n",
    "              WITH DISTINCT c \\n\n",
    "              SET c.pagesFetched = true\", {{ level: level }}) yield value \\n\n",
    "              return value \\n\n",
    "              '''.format(levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def retrieve_page_titles(graph, conditions = (), skip = None, limit = None): \n",
    "    selector = NodeSelector(graph)\n",
    "    selected = list(selector.select(\"Page\"))\n",
    "    \n",
    "    list_of_page_titles = []\n",
    "    \n",
    "    for node in selected:\n",
    "        list_of_page_titles.append(node['pageTitle'])\n",
    "    \n",
    "    return list_of_page_titles;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def strip_markup(text): \n",
    "    \n",
    "    text = re_apostrophes.sub(' ', text)\n",
    "    text = re_display_styles.sub(' ', text)\n",
    "    text = re_newlines.sub(' ', text)\n",
    "    text = re_section_headers.sub(' ', text)\n",
    "    text = re_not_words.sub(' ', text)\n",
    "    text = re_single_words.sub(' ', text)\n",
    "    text = re_duplicate_spaces.sub(' ', text)\n",
    "    text = re_escaped_elements.sub(' ', text)\n",
    "    text = re_cruft.sub(' ', text)\n",
    "    text = re_rename_1.sub(' ', text)\n",
    "    text = re_rename_2.sub(' ', text)\n",
    "    text = re_rename_3.sub(' ', text)\n",
    "    text = re_single_words.sub(' ', text)\n",
    "    \n",
    "    return text;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_streams(page_titles): \n",
    "    text_list = []\n",
    "    meta_list = []\n",
    "    \n",
    "    for title in page_titles:\n",
    "        wikipage = wikipedia.WikipediaPage(title)\n",
    "        text = strip_markup(wikipage.content)\n",
    "        text_list.append(text)\n",
    "        meta_list.append({'title': wikipage.title, \n",
    "                          'categories': wikipage.categories, \n",
    "                          'links': wikipage.links})\n",
    "        \n",
    "    return text_list, meta_list;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Connect to the existing Neo4j graph \n",
    "graph = Graph(password = 'password')\n",
    "\n",
    "# Set up rate limiting for wikipedia library\n",
    "wikipedia.set_rate_limiting(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Delete all existing nodes and relationships that may happen to exist in the graph \n",
    "graph.delete_all()\n",
    "\n",
    "# Create indexes for faster retrieval\n",
    "create_indexes(graph)\n",
    "\n",
    "# Creates the initial category to search from\n",
    "create_root(graph, 'Moment (mathematics)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find categories that are related to existing category \n",
    "fetch_categories(graph, levels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find pages that are related to the category nodes \n",
    "fetch_pages(graph, levels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make a list of page titles from page nodes in the graph \n",
    "page_titles = retrieve_page_titles(graph)\n",
    "\n",
    "# Just demonstrating an element of the page titles list\n",
    "page_titles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a record and metadata stream from a list of page titles \n",
    "texts, metas = generate_streams(page_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a new corpus from the streams made above \n",
    "corpus = textacy.Corpus('en', texts = texts, metadatas = metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Accessing docs by index in a corpus \n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for doc in corpus: \n",
    "    print(doc.metadata['title'])\n",
    "    print(doc.text[:200])\n",
    "    print('\\n===================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0.0
    ]
   },
   "outputs": [],
   "source": [
    "# Create a list of page titles for concepts in Metacademy for 'Bayesian Statistics' \n",
    "page_titles = [\"Probability\", \n",
    "               \"Conditional probability\",\n",
    "               \"Random variable\",\n",
    "               \"Independence (probability theory)\",\n",
    "               \"Bayes' theorem\",\n",
    "               \"Conditional independence\",\n",
    "               \"Bayesian network\"]\n",
    "\n",
    "# Create a text and metadata stream from the page title\n",
    "text_stream, meta_stream = generate_streams(page_titles)\n",
    "\n",
    "# Create a corpus from the streams\n",
    "corpus = textacy.Corpus('en', texts = text_stream, metadatas = meta_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Probability\n",
      "\n",
      "\n",
      "Probability 70\n",
      "Conditional probability 1\n",
      "Random variable 1\n",
      "Independence 0\n",
      "Bayes theorem 0\n",
      "Conditional independence 0\n",
      "Bayesian network 0\n",
      "\n",
      "\n",
      "('probability', 0.2881268859149587)\n",
      "('theory probability', 0.0969393970737268)\n",
      "('event', 0.08998335434823038)\n",
      "('sample space', 0.043998738511272464)\n",
      "('possible result', 0.0386262627667316)\n",
      "('probability theory', 0.03693475802349753)\n",
      "('outcome', 0.022416987331825955)\n",
      "('theory', 0.02194830952898237)\n",
      "('number', 0.021775010236503644)\n",
      "('occur', 0.019219248256534694)\n",
      "\n",
      "=================================================\n",
      "\n",
      " Conditional probability\n",
      "\n",
      "\n",
      "Probability 75\n",
      "Conditional probability 25\n",
      "Random variable 4\n",
      "Independence 1\n",
      "Bayes theorem 0\n",
      "Conditional independence 0\n",
      "Bayesian network 0\n",
      "\n",
      "\n",
      "('conditional probability', 0.22306216750002653)\n",
      "('conditional probability give', 0.08005798920516169)\n",
      "('probability measure', 0.07624636044835287)\n",
      "('event', 0.05491279350932815)\n",
      "('probability', 0.05409721242644268)\n",
      "('event have occur', 0.03639394566970808)\n",
      "('partial conditional probability', 0.03502424004730566)\n",
      "('probability event', 0.033525492777164254)\n",
      "('probability can define', 0.0329929080167432)\n",
      "('value roll die', 0.03151291709134577)\n",
      "\n",
      "=================================================\n",
      "\n",
      " Random variable\n",
      "\n",
      "\n",
      "Probability 64\n",
      "Conditional probability 0\n",
      "Random variable 69\n",
      "Independence 2\n",
      "Bayes theorem 0\n",
      "Conditional independence 0\n",
      "Bayesian network 0\n",
      "\n",
      "\n",
      "('random variable', 0.2655827179880014)\n",
      "('probability density function', 0.12590248834416667)\n",
      "('variable probability distribution', 0.10019799634968052)\n",
      "('continuous random variable', 0.08312961616821135)\n",
      "('probability mass function', 0.05276684296421591)\n",
      "('value random variable', 0.032408039160320534)\n",
      "('cumulative distribution function', 0.027582576602158577)\n",
      "('value', 0.0189061434950012)\n",
      "('possible outcome', 0.016273465269291094)\n",
      "('probability', 0.014569464077271936)\n",
      "\n",
      "=================================================\n",
      "\n",
      " Independence (probability theory)\n",
      "\n",
      "\n",
      "Probability 12\n",
      "Conditional probability 2\n",
      "Random variable 3\n",
      "Independence 10\n",
      "Bayes theorem 0\n",
      "Conditional independence 2\n",
      "Bayesian network 0\n",
      "\n",
      "\n",
      "('set random variable', 0.2201191953747532)\n",
      "('random variable', 0.15568906762835544)\n",
      "('pairwise independent', 0.0633498611575449)\n",
      "('independent', 0.054164265649428105)\n",
      "('draw red card', 0.04160799299400046)\n",
      "('cumulative distribution function', 0.0385005767957654)\n",
      "('event independent', 0.03743334761160766)\n",
      "('event', 0.0351921572199955)\n",
      "('event be independent', 0.025077083491090047)\n",
      "('event be pairwise', 0.02093414504213347)\n",
      "\n",
      "=================================================\n",
      "\n",
      " Bayes' theorem\n",
      "\n",
      "\n",
      "Probability 48\n",
      "Conditional probability 7\n",
      "Random variable 0\n",
      "Independence 0\n",
      "Bayes theorem 0\n",
      "Conditional independence 0\n",
      "Bayesian network 0\n",
      "\n",
      "\n",
      "('bayes theorem', 0.4448132493236982)\n",
      "('probability', 0.072767594527769)\n",
      "('user user user', 0.05647758919704586)\n",
      "('bayes theorem represent', 0.049980720525272915)\n",
      "('initial degree belief', 0.03674978341408104)\n",
      "('bayesian inference', 0.03627553610492095)\n",
      "('degree belief', 0.02457549254651958)\n",
      "('conditional probability', 0.024436926760202437)\n",
      "('event', 0.016573027568912053)\n",
      "('bayesian', 0.007104708811562015)\n",
      "\n",
      "=================================================\n",
      "\n",
      " Conditional independence\n",
      "\n",
      "\n",
      "Probability 18\n",
      "Conditional probability 4\n",
      "Random variable 2\n",
      "Independence 5\n",
      "Bayes theorem 0\n",
      "Conditional independence 2\n",
      "Bayesian network 0\n",
      "\n",
      "\n",
      "('independent give algebra', 0.17876546993769174)\n",
      "('occur provide information', 0.15885278693296576)\n",
      "('independent give', 0.08928287250654703)\n",
      "('probability distribution give', 0.07566440447819878)\n",
      "('random variable', 0.05384803794494435)\n",
      "('get home time', 0.04862022496219501)\n",
      "('conditional probability distribution', 0.04366702554263531)\n",
      "('event', 0.03553589574757233)\n",
      "('independent', 0.032636771041362915)\n",
      "('probability distribution', 0.027140007576859058)\n",
      "\n",
      "=================================================\n",
      "\n",
      " Bayesian network\n",
      "\n",
      "\n",
      "Probability 25\n",
      "Conditional probability 3\n",
      "Random variable 0\n",
      "Independence 3\n",
      "Bayes theorem 0\n",
      "Conditional independence 2\n",
      "Bayesian network 24\n",
      "\n",
      "\n",
      "('bayesian network', 0.5684441232306449)\n",
      "('variable', 0.027532586725537912)\n",
      "('unobserved variable', 0.022935956610408)\n",
      "('conditional probability', 0.01931537419717003)\n",
      "('joint distribution', 0.015308322764617978)\n",
      "('parent variable', 0.015068268723193211)\n",
      "('model', 0.014712677859879614)\n",
      "('network', 0.014602001306876281)\n",
      "('set node', 0.013903627847670878)\n",
      "('probability', 0.013317225107087006)\n",
      "\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# Print out a doc titles and part of the contents \n",
    "# Readability indices don't seem to to be ordered in any meaningful way\n",
    "\n",
    "inverse_doc_freq = corpus.word_doc_freqs(normalize = 'lemma',\n",
    "                            weighting = 'idf')\n",
    "\n",
    "for doc in corpus: \n",
    "    print('\\n', doc.metadata['title'])\n",
    "    print('\\n')\n",
    "    # print(doc.text)\n",
    "    \n",
    "    # keyterms = textacy.keyterms.key_terms_from_semantic_network(doc, n_keyterms = 15)\n",
    "    \n",
    "    keyterms = textacy.keyterms.sgrank(doc, \n",
    "                                       ngrams = (1,2,3),\n",
    "                                       window_width = 50,\n",
    "                                       idf = inverse_doc_freq)\n",
    "    \n",
    "    print('Probability', doc.count(\"probability\"))\n",
    "    print('Conditional probability', doc.count(\"conditional probability\"))\n",
    "    print('Random variable', doc.count(\"random variable\"))\n",
    "    print('Independence', doc.count(\"independence\"))\n",
    "    print('Bayes theorem', doc.count(\"Bayes' theorem\"))\n",
    "    print('Conditional independence', doc.count(\"conditional independence\"))\n",
    "    print('Bayesian network', doc.count(\"Bayesian network\"))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    for i in keyterms:\n",
    "        print(i)\n",
    "        \n",
    "    print('\\n=================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_network = corpus[6]\n",
    "noun_phrases = list(textacy.extract.pos_regex_matches(bayesian_network, r'<DET>? (<NOUN>+ <ADP|CONJ>)* <NOUN>+'))\n",
    "noun_phrases = [str(x) for x in noun_phrases]\n",
    "semantic_network = textacy.network.terms_to_semantic_network(noun_phrases)\n",
    "key_terms = textacy.keyterms.rank_nodes_by_divrank(semantic_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0.0
    ]
   },
   "outputs": [],
   "source": [
    "targets =             ('bayesian network', \n",
    "                       'bayes network',\n",
    "                       'belief network',\n",
    "                       'bayes(ian) network',\n",
    "                       'probabilistic directed acyclic graphical model',\n",
    "                       'probabilistic graphical model',\n",
    "                       'set',\n",
    "                       'variables',\n",
    "                       'conditional dependencies',\n",
    "                       'directed acyclic graph',\n",
    "                       'DAG',\n",
    "                       'probabilistic relationships',\n",
    "                       'network',\n",
    "                       'probabilities',\n",
    "                       'DAGs',\n",
    "                       'nodes',\n",
    "                       'variables',\n",
    "                       'Bayesian',\n",
    "                       'observable quantities',\n",
    "                       'latent variables',\n",
    "                       'unknown parameters',\n",
    "                       'hypotheses',\n",
    "                       'edges',\n",
    "                       'conditionally independent',\n",
    "                       'node',\n",
    "                       'probability function',\n",
    "                       'parent variables',\n",
    "                       'probability',\n",
    "                       'probability distribution',\n",
    "                       'variable',\n",
    "                       'combinations',\n",
    "                       'parents',\n",
    "                       'undirected',\n",
    "                       'cyclic graphs',\n",
    "                       'Markov networks',\n",
    "                       'algorithms',\n",
    "                       'inference',\n",
    "                       'learning',\n",
    "                       'sequences of variables',\n",
    "                       'dynamic Bayesian networks',\n",
    "                       'decision problems',\n",
    "                       'uncertainty',\n",
    "                       'influence diagrams',\n",
    "                       'events',\n",
    "                       'joint probability function',\n",
    "                       'conditional probability formula',\n",
    "                       'nuisance variables',\n",
    "                       'conditional probabilities',\n",
    "                       'CPTs',\n",
    "                       'sums',\n",
    "                       'numerator',\n",
    "                       'denominator',\n",
    "                       'post-intervention joint distribution function',\n",
    "                       'pre-intervention distribution',\n",
    "                       'criterion',\n",
    "                       '\"back-door\"',\n",
    "                       'd-separates',\n",
    "                       'back-door path',\n",
    "                       'arrow',\n",
    "                       '\"sufficient\"',\n",
    "                       '\"admissible\"',\n",
    "                       'set',\n",
    "                       'd-separate',\n",
    "                       'observed',\n",
    "                       'passive observations',\n",
    "                       'observed dependence',\n",
    "                       'causal connection',\n",
    "                       'spurious',\n",
    "                       \"Simpson's paradox\",\n",
    "                       'causal relation',\n",
    "                       'Bayesian network',\n",
    "                       'unobserved variables',\n",
    "                       'do-calculus',\n",
    "                       'terms',\n",
    "                       'expression',\n",
    "                       'relation',\n",
    "                       'estimable',\n",
    "                       'frequency data',\n",
    "                       'dependencies',\n",
    "                       'joint distribution',\n",
    "                       'naive',\n",
    "                       'conditional probabilities',\n",
    "                       'local distributions',\n",
    "                       'parent variables',\n",
    "                       'Bayesian networks',\n",
    "                       'direct dependencies',\n",
    "                       'joint distributions',\n",
    "                       'Bayesian networks',\n",
    "                       'inference',\n",
    "                       'Bayesian network',\n",
    "                       'model', \n",
    "                       'variables',\n",
    "                       'probabilistic',\n",
    "                       'network',\n",
    "                       'state',\n",
    "                       'subset',\n",
    "                       'variables',\n",
    "                       'evidence variables',\n",
    "                       'observed',\n",
    "                       'posterior distribution',\n",
    "                       'posterior',\n",
    "                       'probabilistic inference',\n",
    "                       'universal sufficient statistic',\n",
    "                       'variable subset',\n",
    "                       'expected loss function',\n",
    "                       'probability',\n",
    "                       'decision error',\n",
    "                       \"Bayes' theorem\",\n",
    "                       'complex problems',\n",
    "                       'inference methods',\n",
    "                       'variable elimination',\n",
    "                       'integration',\n",
    "                       'summation',\n",
    "                       'non-observed non-query variables',\n",
    "                       'distributing',\n",
    "                       'sum',\n",
    "                       'product',\n",
    "                       'clique tree propagation',\n",
    "                       'caches',\n",
    "                       'new evidence',\n",
    "                       'propagated',\n",
    "                       'recursive condition',\n",
    "                       'AND/OR search',\n",
    "                       'space-time',\n",
    "                       'efficiency',\n",
    "                       'variable elimination',\n",
    "                       'complexity',\n",
    "                       'exponential',\n",
    "                       'treewidth',\n",
    "                       'inference algorithms',\n",
    "                       'importance sampling',\n",
    "                       'stochastic MCMC simulation',\n",
    "                       'mini-bucket elimination',\n",
    "                       'loopy belief propagation',\n",
    "                       'generalized belief propagation',\n",
    "                       'variational methods',\n",
    "                       'Bayesian network',\n",
    "                       'joint probability distribution',\n",
    "                       'node',\n",
    "                       'probability distribution', \n",
    "                       'conditional',\n",
    "                       'distribution',\n",
    "                       'discrete',\n",
    "                       'Gaussian distributions',\n",
    "                       'constraints',\n",
    "                       'principle of maximum entropy',\n",
    "                       'single distribution',\n",
    "                       'greatest entropy',\n",
    "                       'entropy',\n",
    "                       'dynamic Bayesian network',\n",
    "                       'conditional distribution',\n",
    "                       \"hidden state's\",\n",
    "                       'temporal evolution',\n",
    "                       'entropy rate',\n",
    "                       'implied stochastic process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acyclicity constraints': 0.001098523851074037,\n",
       " 'Another method': 0.002132355999291555,\n",
       " 'DAG': 0.0031583527220999602,\n",
       " 'DAGs': 0.002892634851578673,\n",
       " 'E': 0.0013715148927128955,\n",
       " 'Each node': 0.0011075294243358643,\n",
       " 'Edges': 0.0011742206476861635,\n",
       " 'G S': 0.0010989992135809975,\n",
       " 'Generalizations': 0.0012389594342484178,\n",
       " 'R': 0.0011026074529380755,\n",
       " 'Some care': 0.0019645303219856013,\n",
       " 'The difference': 0.0011988997355738826,\n",
       " 'The distinction between causal': 0.0011308243673686788,\n",
       " 'The distribution': 0.001122790471619892,\n",
       " 'The effect': 0.002007662431159111,\n",
       " 'The model': 0.0017453430776805201,\n",
       " 'The posterior': 0.0011173948691395254,\n",
       " 'The process': 0.0012641206274939712,\n",
       " 'The reliance': 0.0017358711389830143,\n",
       " 'The term': 0.0011328578027584774,\n",
       " 'The time requirement': 0.0011009797056559332,\n",
       " 'These predictions': 0.00175237848116088,\n",
       " 'This approach': 0.0023249555398545062,\n",
       " 'This definition': 0.0012321721733364202,\n",
       " 'This method': 0.0013542176137434452,\n",
       " 'This process': 0.001730008978175413,\n",
       " 'This result': 0.0011916600940244469,\n",
       " 'This shrinkage': 0.0010673850872615588,\n",
       " 'Type': 0.001122037376641017,\n",
       " 'V': 0.001153207028403072,\n",
       " 'What': 0.0011077345957809855,\n",
       " 'X': 0.0014596625910593276,\n",
       " 'Z': 0.0016132720508313038,\n",
       " 'a challenge': 0.0011182459041216162,\n",
       " 'advantage': 0.001488408762439894,\n",
       " 'algorithm': 0.0011457495572095222,\n",
       " 'algorithms': 0.0014924908599308188,\n",
       " 'all arrows': 0.0015828320364859093,\n",
       " 'all edge directions': 0.0016777420594569301,\n",
       " 'all nodes': 0.0013865629193977767,\n",
       " 'all terms': 0.001083592953469214,\n",
       " 'all trails': 0.001713973370296934,\n",
       " 'alternates': 0.001154532419438437,\n",
       " 'amounts memory': 0.0010946209744228566,\n",
       " 'analysis': 0.0011385814896762167,\n",
       " 'answer': 0.0021155974216927513,\n",
       " 'any form': 0.0011903289634769656,\n",
       " 'any member': 0.0016241366344754175,\n",
       " 'applications': 0.0014179044998780322,\n",
       " 'approach': 0.0017960407144634804,\n",
       " 'approaches': 0.0015388617187292832,\n",
       " 'approximation': 0.0012157405480225005,\n",
       " 'approximation algorithm': 0.0012005645721462064,\n",
       " 'architecture': 0.001607725217265399,\n",
       " 'arrow': 0.0013655967166471947,\n",
       " 'arrows': 0.0014471906249084484,\n",
       " 'aspects': 0.001394123003800914,\n",
       " 'assignments': 0.001215575388599032,\n",
       " 'behavior': 0.0017015663729418574,\n",
       " 'belief network': 0.0011268878013358185,\n",
       " 'belief propagation': 0.0013537285269907139,\n",
       " 'beliefs': 0.0015633853768823491,\n",
       " 'bioinformatics gene': 0.00178805639492858,\n",
       " 'biology': 0.0010964389739271465,\n",
       " 'biomonitoring': 0.0010785291158672842,\n",
       " 'blanket': 0.0011898126079886745,\n",
       " 'bucket elimination': 0.0018419515109574598,\n",
       " 'calculus': 0.0014045657050764566,\n",
       " 'case': 0.001119408715311328,\n",
       " 'case inference complexity': 0.0011019616930084172,\n",
       " 'cases': 0.00110962055413068,\n",
       " 'cause': 0.0011401311699479164,\n",
       " 'chain': 0.0018663786944132193,\n",
       " 'changes': 0.0011310090160952546,\n",
       " 'children': 0.001943925910500685,\n",
       " 'classification': 0.001147643508134486,\n",
       " 'classification model': 0.0011189134879758039,\n",
       " 'colleagues': 0.0012867604006137527,\n",
       " 'combinations': 0.0011643443569271498,\n",
       " 'complexity': 0.0011432773802678008,\n",
       " 'conditioning': 0.0013509652940957254,\n",
       " 'conditions': 0.0010902938394185087,\n",
       " 'connection': 0.001155135650038401,\n",
       " 'consideration': 0.00110953705019732,\n",
       " 'constraints': 0.0010933581506100138,\n",
       " 'constraints distribution': 0.0011944575269096193,\n",
       " 'contains': 0.0015427908439038156,\n",
       " 'context': 0.0012698149723156795,\n",
       " 'criterion': 0.0016820915926120976,\n",
       " 'data': 0.0020102182906898344,\n",
       " 'data fusion': 0.0011212848546911954,\n",
       " 'decision problems under uncertainty': 0.001133364081158131,\n",
       " 'decision support systems': 0.001365967745244408,\n",
       " 'definition': 0.0020447317612562158,\n",
       " 'definitions': 0.0013805631443561145,\n",
       " 'denominator': 0.0011086363911512022,\n",
       " 'density functions': 0.0011497434096403697,\n",
       " 'dependence': 0.001903023776711211,\n",
       " 'dependencies': 0.0012996427498682555,\n",
       " 'dependencies nodes': 0.0012162398160931818,\n",
       " 'descendant': 0.0014127252988434698,\n",
       " 'descendants': 0.0015490786308947004,\n",
       " 'deviation': 0.0010992219753548527,\n",
       " 'dimension models': 0.0012036131406697077,\n",
       " 'directional': 0.0011430748605874206,\n",
       " 'directionality': 0.0011365436972345518,\n",
       " 'diseases': 0.0013943834248174372,\n",
       " 'distinction': 0.00112347651389317,\n",
       " 'distribution': 0.0014377725598472399,\n",
       " 'distribution function': 0.0011250139584380876,\n",
       " 'distributions': 0.0011115011257758279,\n",
       " 'distributions variable': 0.0010844641947842966,\n",
       " 'document classification': 0.001140125865386963,\n",
       " 'door': 0.0016768167281346702,\n",
       " 'door criterion': 0.0011248446283382767,\n",
       " 'door path': 0.001199975791270692,\n",
       " 'door paths': 0.0013461904042172661,\n",
       " 'each term': 0.0013678728617202724,\n",
       " 'each variable': 0.001388090423483314,\n",
       " 'ed': 0.0015910215888064133,\n",
       " 'edge': 0.0014490373197586057,\n",
       " 'effect': 0.001127534097488938,\n",
       " 'elimination': 0.0011022502517149641,\n",
       " 'engineering': 0.0016249853564654633,\n",
       " 'entropy': 0.0014384403317931843,\n",
       " 'entry': 0.0016722271504113406,\n",
       " 'epistasis': 0.0011222251237121886,\n",
       " 'error': 0.001092414104449216,\n",
       " 'error with confidence probability': 0.00109216142845087,\n",
       " 'errors': 0.0010987684040079664,\n",
       " 'estimates': 0.0013237852450521707,\n",
       " 'events': 0.0011048385587011016,\n",
       " 'every node': 0.0012764503669572547,\n",
       " 'evidence': 0.0011244539427525623,\n",
       " 'evolution': 0.0017344160897674792,\n",
       " 'example': 0.0029508618144016407,\n",
       " 'expert': 0.0011170072542003146,\n",
       " 'expressions': 0.0011882973857105454,\n",
       " 'forensics': 0.0012487784320465599,\n",
       " 'fork': 0.0012927172244764148,\n",
       " 'fork collider': 0.0015122728245291854,\n",
       " 'form': 0.0011540510169146911,\n",
       " 'formula': 0.0012928455760977495,\n",
       " 'gaming': 0.001160445568020815,\n",
       " 'gene expression analysis': 0.016312891869913478,\n",
       " 'geophysics': 0.0014663551733768941,\n",
       " 'graph': 0.001336677126749152,\n",
       " 'graph DAG': 0.001329515705584342,\n",
       " 'graph DAG For example': 0.0010864705364949194,\n",
       " 'grass': 0.0011450563854751609,\n",
       " 'hand': 0.0011410553749280393,\n",
       " 'humans': 0.0011188492629874444,\n",
       " 'idea': 0.0012564328108207272,\n",
       " 'ideas': 0.001179534829363846,\n",
       " 'image processing': 0.0015922334116252128,\n",
       " 'implementation': 0.0013144878316728747,\n",
       " 'implementations': 0.001683579020606378,\n",
       " 'importance sampling': 0.001187674094233263,\n",
       " 'independence': 0.0011465303212877063,\n",
       " 'independence requirements': 0.14361371130212955,\n",
       " 'independencies': 0.0016133040395942427,\n",
       " 'inference': 0.002050837145680654,\n",
       " 'inference algorithms': 0.001309866839628607,\n",
       " 'inference methods': 0.0011273861548988452,\n",
       " 'inference tasks': 0.0010892324473110214,\n",
       " 'inference within factor': 0.0011401915269953667,\n",
       " 'influence diagrams': 0.0011251725565080695,\n",
       " 'information': 0.0010764475702844613,\n",
       " 'information between variables': 0.001306712070209112,\n",
       " 'information retrieval': 0.0015265796149580284,\n",
       " 'input': 0.0011105147583053416,\n",
       " 'instance': 0.0011098340569566745,\n",
       " 'integration summation': 0.0015225795060561246,\n",
       " 'intervention': 0.001153032350773509,\n",
       " 'intervention distribution': 0.0012982864624944226,\n",
       " 'interventions from data': 0.0018442193247706973,\n",
       " 'introduction for researchers': 0.0014160922054545196,\n",
       " 'knowledge': 0.0015503756159925058,\n",
       " 'language': 0.001432771282061147,\n",
       " 'latent variables': 0.001109645090440282,\n",
       " 'learning': 0.0012605798576715514,\n",
       " 'levels': 0.0012141730854298516,\n",
       " 'likelihood': 0.0012810033614923924,\n",
       " 'likelihood approach': 0.0011055352854994122,\n",
       " 'likelihood compute posterior probability': 0.0015436282399444148,\n",
       " 'likelihood estimate': 0.001638994207282159,\n",
       " 'likelihood estimates': 0.0020313814369314416,\n",
       " 'likelihood posterior': 0.0014355715268175098,\n",
       " 'line Tutorial': 0.0010812053548700776,\n",
       " 'literature': 0.0012945734268824994,\n",
       " 'loopy belief propagation': 0.0013908053552624882,\n",
       " 'loss': 0.0019934306003994034,\n",
       " 'loss function': 0.0016096729328994518,\n",
       " 'machine learning': 0.0014588948437686195,\n",
       " 'machine learning applications': 0.001216740790606266,\n",
       " 'marketing informatics': 0.0015054891386274106,\n",
       " 'maximization': 0.001651134142070638,\n",
       " 'maximum entropy determine': 0.0012629986394325566,\n",
       " 'mean': 0.0011399099398365332,\n",
       " 'measurements': 0.001112411853625912,\n",
       " 'mechanism': 0.0011318811853998994,\n",
       " 'medicine': 0.0010921834843178292,\n",
       " 'method': 0.0019199546293326433,\n",
       " 'methods': 0.0013597119859530213,\n",
       " 'minima': 0.0012164312579597992,\n",
       " 'model': 0.0014112439060569438,\n",
       " 'model type': 0.0012230895602979,\n",
       " 'models': 0.0011342551972864442,\n",
       " 'models with latent variables': 0.0010989482387176975,\n",
       " 'modes reasoning': 0.001199140443953287,\n",
       " 'n': 0.0014099357266209231,\n",
       " 'nature': 0.001126439571998121,\n",
       " 'nets': 0.0016867156674802454,\n",
       " 'network': 0.001470748654984866,\n",
       " 'network representation': 0.0011657407465994508,\n",
       " 'network with respect': 0.0012384862233892312,\n",
       " 'networks': 0.0017140538597039397,\n",
       " 'networks bioinformatics': 0.001894320317358407,\n",
       " 'networks field study': 0.0011343392215023593,\n",
       " 'networks that model': 0.0011436283454786707,\n",
       " 'networks with guarantees': 0.12958609702048643,\n",
       " 'networks without tears': 0.0013243224564299047,\n",
       " 'node': 0.0013940817537771383,\n",
       " 'nodes': 0.0011748419857499197,\n",
       " 'nodes u': 0.0012016478239676544,\n",
       " 'observations': 0.0013924089122914986,\n",
       " 'one': 0.001188375442391779,\n",
       " 'optimization': 0.0020679707996485077,\n",
       " 'order': 0.001226500128657922,\n",
       " 'order deal with problems with thousands variables': 0.0012264767975853823,\n",
       " 'ordering': 0.0011334561242950225,\n",
       " 'orderings': 0.0016208374123178038,\n",
       " 'output': 0.0036538765407848977,\n",
       " 'pairs': 0.0011322929683534257,\n",
       " 'paper': 0.001281275650883382,\n",
       " 'paradox determine': 0.001739078421666502,\n",
       " 'parameter': 0.0010948121716502003,\n",
       " 'parameters': 0.0011556944066894253,\n",
       " 'parameters hypotheses': 0.0012649033686929609,\n",
       " 'parent': 0.0011669536381868257,\n",
       " 'parent nodes': 0.0014972390362010565,\n",
       " 'parent variables': 0.0014180295139401573,\n",
       " 'parents': 0.001109245597562187,\n",
       " 'path': 0.0010980229993926129,\n",
       " 'perform inference': 0.002025528100175507,\n",
       " 'planes': 0.0016387181352915331,\n",
       " 'policy evaluation problems': 0.0012250640105686704,\n",
       " 'posterior distribution': 0.0010922039986845287,\n",
       " 'posterior probability': 0.0016335141251680185,\n",
       " 'posterior values for parameters': 0.005612452657967879,\n",
       " 'posteriors': 0.0011524569246270935,\n",
       " 'priors': 0.0011200764619897522,\n",
       " 'probabilities': 0.0013828860265643241,\n",
       " 'probability': 0.0010979102989440432,\n",
       " 'probability density function with respect product measure': 0.0011213010667130902,\n",
       " 'probability distribution': 0.001130955998254554,\n",
       " 'probability distributions': 0.001145196568782132,\n",
       " 'probability formula': 0.001157272846280515,\n",
       " 'probability function': 0.0011375193380176684,\n",
       " 'probability tables CPTs': 0.0011026716102829168,\n",
       " 'problems': 0.001106412646993524,\n",
       " 'problems with variables': 0.001083381375839715,\n",
       " 'process': 0.0013263450411615094,\n",
       " 'program': 0.0012964944477956387,\n",
       " 'programming': 0.0010930033508386938,\n",
       " 'property': 0.001793721241981339,\n",
       " 'property market': 0.0011192876640339308,\n",
       " 'property with respect': 0.0013734837659670838,\n",
       " 'protein structure': 0.0017229895475507958,\n",
       " 'quantities': 0.0013626746464641755,\n",
       " 'quantity estimable from frequency data': 0.001408762639219896,\n",
       " 'queries': 0.0011622789125575992,\n",
       " 'query': 0.0017270019408562314,\n",
       " 'question': 0.0015294332544186244,\n",
       " 'questions': 0.0013454009921396851,\n",
       " 'rains': 0.00110790321422903,\n",
       " 'recovery algorithm': 0.0015996524990621577,\n",
       " 'regularity conditions': 0.001227164137747143,\n",
       " 'relation': 0.001082218571788155,\n",
       " 'relationships': 0.0011150947126166994,\n",
       " 'relationships between diseases': 0.0011726481557006291,\n",
       " 'replicate samples': 0.0010948049514535587,\n",
       " 'representations': 0.002209318787423133,\n",
       " 'requirement': 0.0014666773828229123,\n",
       " 'restriction': 0.0012189731197185158,\n",
       " 'restrictions': 0.001150651064205422,\n",
       " 'results': 0.0015604817147479375,\n",
       " 'risk analysis': 0.0011684848078004225,\n",
       " 'rules': 0.001138754377132232,\n",
       " 'sample': 0.001165392081660677,\n",
       " 'sample heterogeneity classification problems': 0.0010860551442431231,\n",
       " 'sample uncertainty': 0.0011234523858460787,\n",
       " 'sampler': 0.0011394011880997749,\n",
       " 'samplers': 0.0015579999799093215,\n",
       " 'scale': 0.0011091431749730824,\n",
       " 'scoring function': 0.0020732666681058448,\n",
       " 'search': 0.0011142979177112767,\n",
       " 'search algorithm': 0.0014463215938728844,\n",
       " 'search strategy': 0.0017099534900810768,\n",
       " 'semantics': 0.001116825001907654,\n",
       " 'sense': 0.0011109608394187752,\n",
       " 'separates blocks': 0.0013944516458558331,\n",
       " 'separation': 0.0015968317196127064,\n",
       " 'set': 0.0011918798559941,\n",
       " 'set nodes': 0.0013584730714261142,\n",
       " 'simulation': 0.0010886720292408866,\n",
       " 'software': 0.0010968768196720987,\n",
       " 'solution': 0.0015668093244143842,\n",
       " 'source alternative': 0.0012479180029231287,\n",
       " 'source development': 0.0012310808385845335,\n",
       " 'source package': 0.001086677406143764,\n",
       " 'space': 0.001120850105948987,\n",
       " 'space time tradeoff': 0.0013053318660495368,\n",
       " 'specify': 0.0023528847101122077,\n",
       " 'speech signals protein sequences': 0.0012521520834553215,\n",
       " 'sports betting': 0.0019506469800572924,\n",
       " 'state': 0.0011664112406139372,\n",
       " 'state action': 0.001103149006962459,\n",
       " 'states': 0.0014499094286820821,\n",
       " 'statistic for detection applications': 0.0011259310593424155,\n",
       " 'storage space for values': 0.001724618361910871,\n",
       " 'store': 0.001167918667033899,\n",
       " 'structure': 0.0010787830908025498,\n",
       " 'structure for hundreds variables': 0.0014518268747361507,\n",
       " 'structure with respect that ordering': 0.002388210869761295,\n",
       " 'study design': 0.0013285731742406505,\n",
       " 'subset': 0.001292487944296261,\n",
       " 'surge research approximation algorithms': 0.0203944704117899,\n",
       " 'symptoms': 0.0011121817603068351,\n",
       " 'table entries': 0.0019851441539667425,\n",
       " 'terms': 0.001507143319482761,\n",
       " 'text': 0.0017280950386954588,\n",
       " 'texts': 0.0016019865793500112,\n",
       " 'that simplifies calculations': 0.0012935745672114877,\n",
       " 'the action': 0.0017188769240728573,\n",
       " 'the aim': 0.0011048325700711964,\n",
       " 'the answer': 0.0010909616941188294,\n",
       " 'the approach': 0.001091612507639778,\n",
       " 'the arrows': 0.0010831999605962794,\n",
       " 'the basis': 0.0010825257120128048,\n",
       " 'the case': 0.0011430648635493998,\n",
       " 'the causal networks': 0.0011222795352610405,\n",
       " 'the chain rule': 0.0011432244540466087,\n",
       " 'the complexity approximation': 0.0011180008297134426,\n",
       " 'the computation': 0.00135475860744254,\n",
       " 'the concept tree': 0.0019825867917577233,\n",
       " 'the constraints': 0.001112953362178981,\n",
       " 'the definition': 0.0013839586008078852,\n",
       " 'the dependencies': 0.0011158630112693552,\n",
       " 'the diagram': 0.0011936025842656823,\n",
       " 'the difficulty': 0.0013392250859248825,\n",
       " 'the directionality': 0.001077543337229969,\n",
       " 'the distinction': 0.0011884899855091886,\n",
       " 'the distribution': 0.0014651298131470533,\n",
       " 'the effect': 0.0011726637265064568,\n",
       " 'the efficiency': 0.0014168824498856408,\n",
       " 'the entropy rate': 0.0015717033291211293,\n",
       " 'the error approximation': 0.0017145234783517435,\n",
       " 'the evidence variables': 0.001079949570663032,\n",
       " 'the example': 0.0012607906338439328,\n",
       " 'the expansion': 0.002253578460673721,\n",
       " 'the expectation maximization algorithm': 0.001752785471743745,\n",
       " 'the expression that relation': 0.036096523485769874,\n",
       " 'the fact': 0.0011735337753418184,\n",
       " 'the factor': 0.0017413059122704906,\n",
       " 'the following': 0.001077306348316233,\n",
       " 'the form': 0.001603349499749967,\n",
       " 'the graph': 0.0011217941414132094,\n",
       " 'the graph acyclic': 0.0011177924337063716,\n",
       " 'the graph structure': 0.001669508969389614,\n",
       " 'the graphs': 0.0011205700169724206,\n",
       " 'the grass': 0.0017301832797336726,\n",
       " 'the hierarchy': 0.0017489102181446766,\n",
       " 'the impact': 0.0011322450963354798,\n",
       " 'the independence': 0.0012198835788334323,\n",
       " 'the individual': 0.0011366257619030526,\n",
       " 'the input information': 0.00112499720474029,\n",
       " 'the interface': 0.0011011251252381021,\n",
       " 'the learning process': 0.002607161130816164,\n",
       " 'the likelihood': 0.0011249746831134553,\n",
       " 'the links': 0.001254224486696705,\n",
       " 'the model parameters': 0.0011912833190396495,\n",
       " 'the names': 0.001098252897636695,\n",
       " 'the network': 0.0017480167676010374,\n",
       " 'the network n.': 0.0017231167635989278,\n",
       " 'the network structure': 0.0011225621730771786,\n",
       " 'the network treewidth': 0.001101525934742747,\n",
       " 'the node': 0.001298984076127991,\n",
       " 'the number': 0.0011196010037838036,\n",
       " 'the number variables': 0.004578308299963744,\n",
       " 'the numerator': 0.001117921323385793,\n",
       " 'the observations': 0.0011485217837094114,\n",
       " 'the one': 0.001311402811038267,\n",
       " 'the parameters': 0.002012946920516576,\n",
       " 'the parent candidate': 0.001269525890474482,\n",
       " 'the parents X': 0.0012988516026614324,\n",
       " 'the post intervention': 0.0012511387081984497,\n",
       " 'the posterior': 0.0014498558557839122,\n",
       " 'the posterior distribution': 0.0011587445298970273,\n",
       " 'the posterior distribution variables': 0.0014980561801532022,\n",
       " 'the posterior probability': 0.0014070975741019335,\n",
       " 'the presence': 0.0014995303147518485,\n",
       " 'the prior': 0.0011516222909324803,\n",
       " 'the probabilities': 0.001350269828459142,\n",
       " 'the probability': 0.00146440235953394,\n",
       " 'the probability decision error': 0.0013296515158578608,\n",
       " 'the probability density function': 0.0011071571395036167,\n",
       " 'the probability distribution': 0.0019644038018067243,\n",
       " 'the probability function': 0.001469187084563019,\n",
       " 'the probability probability distribution': 0.0016555107353600409,\n",
       " 'the probability rain': 0.0016790422626352533,\n",
       " 'the problem optimization problem': 0.0020643113443297684,\n",
       " 'the process': 0.0013265019162222408,\n",
       " 'the product': 0.0016626952044207627,\n",
       " 'the product clique tree propagation': 0.0012006219282746306,\n",
       " 'the properties': 0.0011335218295550839,\n",
       " 'the quantities': 0.0011720134962176704,\n",
       " 'the rain': 0.0010959482897885471,\n",
       " 'the relationships causal': 0.0010935997256132696,\n",
       " 'the rest': 0.0016452633963594957,\n",
       " 'the score': 0.0012915666048058016,\n",
       " 'the search space': 0.001077740476730866,\n",
       " 'the set': 0.0011100825254822357,\n",
       " 'the set descendants': 0.001705138244227045,\n",
       " 'the set nodes': 0.0017415602724160906,\n",
       " 'the situation': 0.0010880857093486273,\n",
       " 'the skeleton': 0.0016846199209742919,\n",
       " 'the skeletons': 0.001077101019867015,\n",
       " 'the space network structures': 0.001107911263284496,\n",
       " 'the sprinkler': 0.0012654128307864527,\n",
       " 'the state subset variables': 0.0016882472177241414,\n",
       " 'the structure': 0.001437242102420488,\n",
       " 'the sub class': 0.002014268041714622,\n",
       " 'the sum': 0.0013271051562549585,\n",
       " 'the sums': 0.0010819829076511801,\n",
       " 'the task': 0.0011214100591104526,\n",
       " 'the term': 0.0012632162582343707,\n",
       " 'the training data': 0.0011407196681436605,\n",
       " 'the treewidth': 0.0016994152614794697,\n",
       " 'the uncertainty': 0.0011343906448756371,\n",
       " 'the use': 0.0011045027395362671,\n",
       " 'the values': 0.0011245805345469402,\n",
       " 'the variable': 0.0014901516620044275,\n",
       " 'the variables': 0.0017419954526656093,\n",
       " 'these complexity results': 0.0013095232334127034,\n",
       " 'these methods': 0.001413026436211622,\n",
       " 'these semantics': 0.0012018175738403004,\n",
       " 'this case': 0.0010821710261501372,\n",
       " 'this context': 0.0011025991555538737,\n",
       " 'this path': 0.0011637867127427004,\n",
       " 'this problem': 0.0012790389249025245,\n",
       " 'this process': 0.0014311404014209674,\n",
       " 'this relationship': 0.0014380309501691635,\n",
       " 'those parents': 0.0011175411094856223,\n",
       " 'those vertices': 0.001077154927924371,\n",
       " 'time': 0.0010876992428870513,\n",
       " 'time hypothesis': 0.0012208856170046014,\n",
       " 'times': 0.0011831060325115834,\n",
       " 'tractable': 0.0014211418802830696,\n",
       " 'tractable inference': 0.0011174287862706583,\n",
       " 'trail': 0.0011050067463333798,\n",
       " 'trail loop': 0.0011039280771426281,\n",
       " 'treewidth': 0.0011485077739633487,\n",
       " 'triplets': 0.0011404811584093957,\n",
       " 'tutorial': 0.0011462126378069598,\n",
       " 'type': 0.0011592951784891946,\n",
       " 'types': 0.0014907448483851128,\n",
       " 'use': 0.0010952438358852801,\n",
       " 'value x.': 0.0011262425338798138,\n",
       " 'values': 0.0012861474158725828,\n",
       " 'variables': 0.0013502594642258157,\n",
       " 'variables table': 0.001312942363426981,\n",
       " 'variance algorithm': 0.0014501748780042368,\n",
       " 'variant': 0.001120818560801657,\n",
       " 'volcano monitoring law': 0.0020653871751844352,\n",
       " 'way': 0.0018785143830392106,\n",
       " 'wish': 0.0018470134693183626,\n",
       " 'work': 0.0029775752181273314,\n",
       " 'world applications': 0.0012065920827831831}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.preprocess import fix_bad_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "413px",
    "left": "46px",
    "right": "126px",
    "top": "164px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
