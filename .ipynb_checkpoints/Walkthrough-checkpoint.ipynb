{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TODO\n",
    "- Finish \"Most Discriminating Terms\"\n",
    "- Finish \"Group Vectorizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import Statements \n",
    "import wikipedia\n",
    "import textacy\n",
    "import textacy.keyterms\n",
    "from textacy.datasets.wikipedia import strip_markup\n",
    "\n",
    "text = wikipedia.WikipediaPage('Set (mathematics)').content\n",
    "text = strip_markup(text)\n",
    "doc = textacy.Doc(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extract\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Bag of Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'s\": 2,\n",
       " \"'s definition\": 1,\n",
       " \"'s definition turn\": 1,\n",
       " \"'s element\": 1,\n",
       " '-PRON-': 1,\n",
       " '-PRON- can illustrate': 1,\n",
       " '19th': 1,\n",
       " '19th century': 1,\n",
       " '19}.': 1,\n",
       " '2,4,6}.': 1,\n",
       " '2,4,6}. the': 1,\n",
       " '2,4,6}. the concept': 1,\n",
       " '4}.': 2,\n",
       " '6}.': 2,\n",
       " '6}. however': 1,\n",
       " '6}. moreover': 1,\n",
       " '=': 12,\n",
       " '= b': 1,\n",
       " '= c': 1,\n",
       " '= d.': 1,\n",
       " 'a': 32,\n",
       " 'a =': 3,\n",
       " 'a = b': 1,\n",
       " 'a = c': 1,\n",
       " 'a and b': 1,\n",
       " 'a be call': 1,\n",
       " 'a be contain': 1,\n",
       " 'a be say': 1,\n",
       " 'a more general': 1,\n",
       " 'a partition': 1,\n",
       " 'a set': 2,\n",
       " 'a ⊂': 1,\n",
       " 'a ⊂ b': 1,\n",
       " 'a ⊆': 5,\n",
       " 'a ⊆ a.': 1,\n",
       " 'a ⊆ b': 3,\n",
       " 'a ⊆ u.': 1,\n",
       " 'a ⊊': 2,\n",
       " 'a ⊊ b': 2,\n",
       " 'a.': 4,\n",
       " 'a. the': 1,\n",
       " 'a. the relationship': 1,\n",
       " 'abbreviate': 1,\n",
       " 'advanced': 1,\n",
       " 'advanced concept': 1,\n",
       " 'age': 1,\n",
       " 'alphabet': 1,\n",
       " 'an': 2,\n",
       " 'an extensional': 1,\n",
       " 'an extensional definition': 1,\n",
       " 'an obvious': 1,\n",
       " 'anschauung': 1,\n",
       " 'author': 2,\n",
       " 'author use': 1,\n",
       " 'axiom': 1,\n",
       " 'axiomatic': 1,\n",
       " 'axiomatic set': 1,\n",
       " 'axiomatic set theory': 1,\n",
       " 'b': 35,\n",
       " 'b =': 2,\n",
       " 'b = d.': 1,\n",
       " 'b and b': 2,\n",
       " 'b be equal': 1,\n",
       " 'b contain': 1,\n",
       " 'b contain a.': 1,\n",
       " 'b include': 1,\n",
       " 'b include a': 1,\n",
       " 'b ⊃': 1,\n",
       " 'b ⊃ a': 1,\n",
       " 'b ⊆': 1,\n",
       " 'b ⊆ a.': 1,\n",
       " 'b ⊇': 2,\n",
       " 'b ⊇ a': 2,\n",
       " 'b ⊋': 2,\n",
       " 'b ⊋ a': 2,\n",
       " 'b.': 1,\n",
       " 'bar': 1,\n",
       " 'basic': 1,\n",
       " 'basic property': 1,\n",
       " 'beginning': 1,\n",
       " 'begründung': 1,\n",
       " 'begründung der': 1,\n",
       " 'begründung der transfiniten': 1,\n",
       " 'beiträge': 1,\n",
       " 'beiträge zur': 1,\n",
       " 'beiträge zur begründung': 1,\n",
       " 'belong': 2,\n",
       " 'belong to b': 2,\n",
       " 'bernard': 1,\n",
       " 'bernard bolzano': 1,\n",
       " 'blue': 2,\n",
       " 'bolzano': 1,\n",
       " 'brace': 2,\n",
       " 'bracket': 1,\n",
       " 'builder': 1,\n",
       " 'builder notation': 1,\n",
       " 'c': 2,\n",
       " 'c =': 1,\n",
       " 'c and b': 1,\n",
       " 'call': 4,\n",
       " 'call a proper': 1,\n",
       " 'call element': 1,\n",
       " 'call inclusion': 1,\n",
       " 'call the extensionality': 1,\n",
       " 'cantor': 2,\n",
       " \"cantor 's\": 1,\n",
       " \"cantor 's definition\": 1,\n",
       " 'capital': 1,\n",
       " 'capital letter': 1,\n",
       " 'card': 1,\n",
       " 'card suit': 1,\n",
       " 'century': 1,\n",
       " 'choice': 1,\n",
       " 'choice of specify': 1,\n",
       " 'coin': 1,\n",
       " 'coin by bernard': 1,\n",
       " 'collection': 3,\n",
       " 'collection of axiom': 1,\n",
       " 'collection of distinct': 2,\n",
       " 'collectively': 1,\n",
       " 'collectively -PRON- form': 1,\n",
       " 'colon': 2,\n",
       " 'color': 1,\n",
       " 'concept': 2,\n",
       " 'concept be teach': 1,\n",
       " 'consider': 3,\n",
       " 'consider collectively': 1,\n",
       " 'consider separately': 1,\n",
       " 'contain': 3,\n",
       " 'contain a.': 1,\n",
       " 'contain a. the': 1,\n",
       " 'contain in b': 1,\n",
       " 'contain s': 1,\n",
       " 'containment': 1,\n",
       " 'context': 1,\n",
       " 'continue': 1,\n",
       " 'conventionally': 1,\n",
       " 'conventionally denote': 1,\n",
       " 'curly': 1,\n",
       " 'curly bracket': 1,\n",
       " 'd': 1,\n",
       " 'd =': 1,\n",
       " 'd.': 1,\n",
       " 'define': 4,\n",
       " 'define collection': 1,\n",
       " 'definite': 1,\n",
       " 'definition': 8,\n",
       " 'definition be denote': 1,\n",
       " 'definition list': 1,\n",
       " 'definition list set': 1,\n",
       " 'definition of set': 1,\n",
       " 'definition turn': 1,\n",
       " 'degree': 1,\n",
       " 'denote': 4,\n",
       " 'denote by enclose': 1,\n",
       " 'denote with capital': 1,\n",
       " 'denote x': 1,\n",
       " 'denote x ∈': 1,\n",
       " 'der': 1,\n",
       " 'der transfiniten': 1,\n",
       " 'der transfiniten mengenlehre': 1,\n",
       " 'derive': 1,\n",
       " 'describe': 2,\n",
       " 'describe set': 1,\n",
       " 'description': 2,\n",
       " 'develop': 1,\n",
       " 'diagram': 1,\n",
       " 'diagram be teach': 1,\n",
       " 'differ': 1,\n",
       " 'different': 2,\n",
       " 'different author': 1,\n",
       " 'different set': 1,\n",
       " 'differently': 1,\n",
       " 'differently by different': 1,\n",
       " 'distinct': 4,\n",
       " 'distinct object': 4,\n",
       " 'e': 1,\n",
       " 'e =': 1,\n",
       " 'education': 1,\n",
       " 'element': 10,\n",
       " 'element of b': 1,\n",
       " 'element or member': 1,\n",
       " 'element x': 1,\n",
       " 'elementary': 1,\n",
       " 'elementary topic': 1,\n",
       " 'ellipsis': 2,\n",
       " 'enclose': 1,\n",
       " 'enclose the list': 1,\n",
       " 'end': 1,\n",
       " 'english': 1,\n",
       " 'enumeration': 1,\n",
       " 'enumeration of member': 1,\n",
       " 'equal': 4,\n",
       " 'equivalently': 1,\n",
       " 'establish': 1,\n",
       " 'establish by ⊆': 1,\n",
       " 'every': 1,\n",
       " 'every set': 1,\n",
       " 'exactly': 2,\n",
       " 'exactly identical': 1,\n",
       " 'example': 7,\n",
       " 'expression': 1,\n",
       " 'expression a': 1,\n",
       " 'expression a ⊂': 1,\n",
       " 'extension': 1,\n",
       " 'extensional': 2,\n",
       " 'extensional definition': 2,\n",
       " 'extensionality': 2,\n",
       " 'extensionality of set': 1,\n",
       " 'extensionally': 2,\n",
       " 'f': 6,\n",
       " 'f =': 2,\n",
       " 'f and green': 1,\n",
       " 'fact': 1,\n",
       " 'flag': 1,\n",
       " 'following': 1,\n",
       " 'following definition': 1,\n",
       " 'for': 6,\n",
       " 'for example': 3,\n",
       " 'for instance': 1,\n",
       " 'for set': 1,\n",
       " 'for technical': 1,\n",
       " 'for technical reason': 1,\n",
       " 'form': 3,\n",
       " 'form a single': 1,\n",
       " 'form n2': 1,\n",
       " 'form n2 −': 1,\n",
       " 'foundation': 1,\n",
       " 'founder': 1,\n",
       " 'founder of set': 1,\n",
       " 'french': 1,\n",
       " 'french flag': 1,\n",
       " 'fundamental': 1,\n",
       " 'fundamental in mathematic': 1,\n",
       " 'gathering': 1,\n",
       " 'general': 1,\n",
       " 'general form': 1,\n",
       " 'georg': 1,\n",
       " 'georg cantor': 1,\n",
       " 'german': 1,\n",
       " 'german word': 1,\n",
       " 'german word menge': 1,\n",
       " 'give': 1,\n",
       " 'give the following': 1,\n",
       " 'green': 1,\n",
       " 'green ∉': 1,\n",
       " 'green ∉ b.': 1,\n",
       " 'hence': 1,\n",
       " 'however': 1,\n",
       " 'identical': 1,\n",
       " 'identity': 1,\n",
       " 'if': 4,\n",
       " 'if a': 1,\n",
       " 'if b': 1,\n",
       " 'if every member': 1,\n",
       " 'if y': 1,\n",
       " 'illustrate': 1,\n",
       " 'important': 1,\n",
       " 'important point': 1,\n",
       " 'in': 6,\n",
       " 'in an extensional': 1,\n",
       " 'in mathematic': 2,\n",
       " 'in mathematic education': 1,\n",
       " 'in the example': 1,\n",
       " 'in this notation': 1,\n",
       " 'in this usage': 1,\n",
       " 'inadequate': 1,\n",
       " 'include': 1,\n",
       " 'include a': 1,\n",
       " 'inclusion': 1,\n",
       " 'inclusion or containment': 1,\n",
       " 'inclusive': 1,\n",
       " 'indicate': 1,\n",
       " 'infinite': 1,\n",
       " 'infinitely': 1,\n",
       " 'infinitely many member': 1,\n",
       " 'instance': 3,\n",
       " 'instead': 1,\n",
       " 'integer': 5,\n",
       " 'intensional': 2,\n",
       " 'intensional definition': 1,\n",
       " 'intensional specification': 1,\n",
       " 'intensionally': 1,\n",
       " 'intensionally or extensionally': 1,\n",
       " 'interpret': 1,\n",
       " 'irrelevant': 1,\n",
       " 'know': 1,\n",
       " 'letter': 2,\n",
       " 'list': 6,\n",
       " 'list be irrelevant': 1,\n",
       " 'list continue': 1,\n",
       " 'list each member': 1,\n",
       " 'list of member': 1,\n",
       " 'list set': 1,\n",
       " 'list set member': 1,\n",
       " 'man': 1,\n",
       " 'mathematic': 5,\n",
       " 'mathematic education': 1,\n",
       " 'mean': 3,\n",
       " 'meaning': 1,\n",
       " 'member': 13,\n",
       " 'member be ♠': 1,\n",
       " 'member in curly': 1,\n",
       " 'member multiple': 1,\n",
       " 'member multiple time': 1,\n",
       " 'member of b': 1,\n",
       " 'member of set': 2,\n",
       " 'membership': 1,\n",
       " 'menge': 1,\n",
       " 'mengenlehre': 1,\n",
       " 'moreover': 1,\n",
       " 'multiple': 1,\n",
       " 'multiple time': 1,\n",
       " 'n': 5,\n",
       " 'n ≤': 2,\n",
       " 'n ≤ 19}.': 1,\n",
       " 'n2': 3,\n",
       " 'n2 −': 3,\n",
       " 'nearly': 1,\n",
       " 'nonempty': 1,\n",
       " 'nonempty subset': 1,\n",
       " 'notation': 3,\n",
       " 'notation with brace': 1,\n",
       " 'notion': 2,\n",
       " 'number': 5,\n",
       " 'object': 7,\n",
       " 'object of b': 1,\n",
       " 'object when consider': 1,\n",
       " 'obvious': 2,\n",
       " 'obvious but useful': 1,\n",
       " 'obvious way': 1,\n",
       " 'one': 2,\n",
       " 'one way': 1,\n",
       " 'order': 1,\n",
       " 'paradoxes': 1,\n",
       " 'partition': 1,\n",
       " 'people': 2,\n",
       " 'perception': 1,\n",
       " 'perception anschauung': 1,\n",
       " 'perfect': 1,\n",
       " 'perfect square': 1,\n",
       " 'play': 1,\n",
       " 'play card': 1,\n",
       " 'play card suit': 1,\n",
       " 'point': 1,\n",
       " 'positive': 3,\n",
       " 'positive even number': 1,\n",
       " 'positive integer': 2,\n",
       " 'power': 4,\n",
       " 'power set': 4,\n",
       " 'power set contain': 1,\n",
       " 'precisely': 1,\n",
       " 'primitive': 1,\n",
       " 'primitive notion': 1,\n",
       " 'pronounce': 1,\n",
       " 'pronounce a': 1,\n",
       " 'proper': 4,\n",
       " 'proper subset': 3,\n",
       " 'proper superset': 1,\n",
       " 'property': 3,\n",
       " 'property be call': 1,\n",
       " 'property of set': 1,\n",
       " 'range': 1,\n",
       " 'read': 3,\n",
       " 'read as b': 1,\n",
       " 'reason': 1,\n",
       " 'red': 1,\n",
       " 'red}.': 1,\n",
       " 'relationship': 1,\n",
       " 'relationship between set': 1,\n",
       " 'render': 1,\n",
       " 'require': 1,\n",
       " 'respect': 1,\n",
       " 'respectively': 2,\n",
       " 'respectively b': 2,\n",
       " 'respectively b ⊇': 1,\n",
       " 'respectively b ⊋': 1,\n",
       " 'right': 1,\n",
       " 'rigor': 1,\n",
       " 'rigor be require': 1,\n",
       " 'rule': 1,\n",
       " 'rule or semantic': 1,\n",
       " 's': 5,\n",
       " 's.': 2,\n",
       " 's. for': 1,\n",
       " 's. for example': 1,\n",
       " 's. the': 1,\n",
       " 's. the power': 1,\n",
       " 'say': 1,\n",
       " 'second': 1,\n",
       " 'second way': 1,\n",
       " 'seemingly': 1,\n",
       " 'seemingly different': 1,\n",
       " 'seemingly different set': 1,\n",
       " 'semantic': 1,\n",
       " 'semantic description': 1,\n",
       " 'separately': 1,\n",
       " 'sequence': 1,\n",
       " 'sequence or tuple': 1,\n",
       " 'set': 68,\n",
       " \"set 's\": 1,\n",
       " \"set 's element\": 1,\n",
       " 'set a': 3,\n",
       " 'set a =': 1,\n",
       " 'set and x': 1,\n",
       " 'set b': 1,\n",
       " 'set be conventionally': 1,\n",
       " 'set be define': 1,\n",
       " 'set be equal': 2,\n",
       " 'set be list': 1,\n",
       " 'set contain': 1,\n",
       " 'set contain s': 1,\n",
       " 'set either intensionally': 1,\n",
       " 'set establish': 1,\n",
       " 'set f': 1,\n",
       " 'set have infinitely': 1,\n",
       " 'set member': 2,\n",
       " 'set member multiple': 1,\n",
       " 'set of color': 1,\n",
       " 'set of nonempty': 1,\n",
       " 'set of positive': 1,\n",
       " 'set of size': 1,\n",
       " 'set s': 2,\n",
       " 'set theory': 3,\n",
       " 'set which differ': 1,\n",
       " 'set whose member': 1,\n",
       " 'single': 1,\n",
       " 'single set': 1,\n",
       " 'size': 1,\n",
       " 'small': 1,\n",
       " 'small integer': 1,\n",
       " 'so': 1,\n",
       " 'sometimes': 1,\n",
       " 'sometimes the vertical': 1,\n",
       " 'specification': 1,\n",
       " 'specify': 3,\n",
       " 'specify a set': 1,\n",
       " 'specify extensionally': 1,\n",
       " 'specify the member': 1,\n",
       " 'square': 1,\n",
       " 'subset': 13,\n",
       " 'subset of b': 3,\n",
       " 'subset of s': 1,\n",
       " 'subset of s.': 2,\n",
       " 'suit': 1,\n",
       " 'superset': 2,\n",
       " 'superset of a': 2,\n",
       " 'take': 1,\n",
       " 'teach': 2,\n",
       " 'technical': 1,\n",
       " 'technical reason': 1,\n",
       " 'the': 13,\n",
       " 'the concept': 1,\n",
       " 'the empty set': 1,\n",
       " 'the expression': 1,\n",
       " 'the expression a': 1,\n",
       " 'the german': 1,\n",
       " 'the german word': 1,\n",
       " 'the most basic': 1,\n",
       " 'the notation': 1,\n",
       " 'the object': 1,\n",
       " 'the paradoxes': 1,\n",
       " 'the power': 2,\n",
       " 'the power set': 2,\n",
       " 'the relationship': 1,\n",
       " 'the second': 1,\n",
       " 'the second way': 1,\n",
       " 'the set': 1,\n",
       " 'theory': 3,\n",
       " 'there': 1,\n",
       " 'thought': 1,\n",
       " 'thus': 1,\n",
       " 'thus the set': 1,\n",
       " 'time': 2,\n",
       " 'today': 1,\n",
       " 'topic': 1,\n",
       " 'transfiniten': 1,\n",
       " 'transfiniten mengenlehre': 1,\n",
       " 'tuple': 1,\n",
       " 'turn': 1,\n",
       " 'u.': 1,\n",
       " 'ubiquitous': 1,\n",
       " 'universal': 1,\n",
       " 'universal set': 1,\n",
       " 'university': 1,\n",
       " 'university degree': 1,\n",
       " 'unlike': 1,\n",
       " 'usage': 1,\n",
       " 'use': 3,\n",
       " 'use axiomatic': 1,\n",
       " 'use axiomatic set': 1,\n",
       " 'useful': 1,\n",
       " 'useful identity': 1,\n",
       " 'venn': 1,\n",
       " 'venn diagram': 1,\n",
       " 'vertical': 1,\n",
       " 'vertical bar': 1,\n",
       " 'way': 4,\n",
       " 'way of describe': 1,\n",
       " 'white': 2,\n",
       " 'word': 1,\n",
       " 'word menge': 1,\n",
       " 'work': 1,\n",
       " 'work the': 1,\n",
       " 'work the paradoxes': 1,\n",
       " 'write': 6,\n",
       " 'write a': 2,\n",
       " 'write a ⊆': 1,\n",
       " 'write a ⊊': 1,\n",
       " 'write as y': 1,\n",
       " 'write b': 1,\n",
       " 'write b ⊇': 1,\n",
       " 'x': 5,\n",
       " 'x belong': 1,\n",
       " 'x in s': 1,\n",
       " 'x ∈': 1,\n",
       " 'x ∈ b': 1,\n",
       " 'y': 3,\n",
       " 'y ∉': 1,\n",
       " 'y ∉ b': 1,\n",
       " 'young': 1,\n",
       " 'young age': 1,\n",
       " 'zur': 1,\n",
       " 'zur begründung': 1,\n",
       " 'zur begründung der': 1,\n",
       " '|': 1,\n",
       " '∅': 1,\n",
       " '∅ ⊆': 1,\n",
       " '∅ ⊆ a.': 1,\n",
       " '∈': 3,\n",
       " '∈ a': 1,\n",
       " '∈ b': 1,\n",
       " '∈ f': 1,\n",
       " '∉': 3,\n",
       " '∉ b': 1,\n",
       " '∉ b.': 1,\n",
       " '∉ f': 1,\n",
       " '−': 3,\n",
       " '≤': 4,\n",
       " '≤ 19}.': 1,\n",
       " '≤ n': 2,\n",
       " '≤ n ≤': 2,\n",
       " '⊂': 1,\n",
       " '⊂ b': 1,\n",
       " '⊃': 1,\n",
       " '⊃ a': 1,\n",
       " '⊆': 10,\n",
       " '⊆ a.': 3,\n",
       " '⊆ b': 3,\n",
       " '⊆ be call': 1,\n",
       " '⊆ u.': 1,\n",
       " '⊇': 2,\n",
       " '⊇ a': 2,\n",
       " '⊊': 2,\n",
       " '⊊ b': 2,\n",
       " '⊋': 2,\n",
       " '⊋ a': 2,\n",
       " '♠': 1,\n",
       " '♣': 1,\n",
       " '♥': 1,\n",
       " '♦': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.to_bag_of_terms(ngrams = (1,2,3),\n",
    "                    named_entities = False,\n",
    "                    normalize = 'lemma',\n",
    "                    weighting = 'count',\n",
    "                    as_strings = True,\n",
    "                    filter_stops = True,\n",
    "                    filter_nums = True,\n",
    "                    drop_determiners = True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "named_entities = textacy.extract.named_entities(doc,\n",
    "                                                include_types = None,\n",
    "                                                exclude_types = 'NUMERIC',\n",
    "                                                drop_determiners = True,\n",
    "                                                min_freq = 1)\n",
    "list(named_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "one_grams = textacy.extract.ngrams(doc,\n",
    "                                   1, \n",
    "                                   filter_stops = True,\n",
    "                                   filter_punct = True,\n",
    "                                   filter_nums = True,\n",
    "                                   include_pos = None,\n",
    "                                   exclude_pos = None,\n",
    "                                   min_freq = 1)\n",
    "list(one_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "two_grams = textacy.extract.ngrams(doc,\n",
    "                                   2, \n",
    "                                   filter_stops = True,\n",
    "                                   filter_punct = True,\n",
    "                                   filter_nums = True,\n",
    "                                   include_pos = None,\n",
    "                                   exclude_pos = None,\n",
    "                                   min_freq = 1)\n",
    "list(two_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "three_grams = textacy.extract.ngrams(doc,\n",
    "                                     3, \n",
    "                                     filter_stops = True,\n",
    "                                     filter_punct = True,\n",
    "                                     filter_nums = True,\n",
    "                                     include_pos = None,\n",
    "                                     exclude_pos = None,\n",
    "                                     min_freq = 1)\n",
    "\n",
    "list(three_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## POS Regex Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = textacy.extract.pos_regex_matches(doc, \"r’<NOUN>+’\")\n",
    "list(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Noun Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "noun_chunks = textacy.extract.noun_chunks(doc,\n",
    "                                          drop_determiners = True,\n",
    "                                          min_freq = 1)\n",
    "\n",
    "list(noun_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Semi-structured Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "statements = textacy.extract.semistructured_statements(doc, \n",
    "                                                     'set',\n",
    "                                                      cue = 'be',\n",
    "                                                      ignore_entity_case = True,\n",
    "                                                      min_n_words = 1,\n",
    "                                                      max_n_words = 20)\n",
    "\n",
    "list(statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## SVO Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "triples = textacy.extract.subject_verb_object_triples(doc)\n",
    "list(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "words = textacy.extract.words(doc,\n",
    "                              filter_stops = True,\n",
    "                              filter_punct = True,\n",
    "                              filter_nums = True,\n",
    "                              include_pos = None,\n",
    "                              exclude_pos = None,\n",
    "                              min_freq = 1)\n",
    "list(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyterms\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Aggregate-term variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'S'}, {'e'}, {'t'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants = textacy.keyterms.aggregate_term_variants(('Set'),\n",
    "                                                    fuzzy_dedupe = True)    \n",
    "list(variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Key Terms from Semantic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('set', 0.0799725657654564),\n",
       " ('b', 0.029121585278008108),\n",
       " ('a', 0.02326949864817083),\n",
       " ('member', 0.020217515912656796),\n",
       " ('subset', 0.01575659229341563),\n",
       " ('example', 0.01518665101845617),\n",
       " ('definition', 0.014914289081537276),\n",
       " ('element', 0.014558805365359551),\n",
       " ('number', 0.013241001115891474),\n",
       " ('f', 0.01311706956666036)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyterms_from_network = textacy.keyterms.key_terms_from_semantic_network(doc,\n",
    "                                                                         normalize = 'lemma',\n",
    "                                                                         window_width = 2,\n",
    "                                                                         edge_weighting = 'binary',\n",
    "                                                                         ranking_algo = 'pagerank',\n",
    "                                                                         join_key_words = False,\n",
    "                                                                         n_keyterms = 10)\n",
    "keyterms_from_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Most Discriminating Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# discriminating_terms = textacy.keyterms.most_discriminating_terms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rank Nodes by Best Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0,
     5
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mathematic',\n",
       " 'subset',\n",
       " '1',\n",
       " 'element',\n",
       " 'for',\n",
       " 'object',\n",
       " 'set',\n",
       " '3',\n",
       " '6',\n",
       " '2',\n",
       " 'in',\n",
       " 'f',\n",
       " 'member',\n",
       " 'definition',\n",
       " 'a',\n",
       " 'number',\n",
       " '4',\n",
       " 'the',\n",
       " 'write',\n",
       " '⊆',\n",
       " 'example',\n",
       " '=',\n",
       " 'list',\n",
       " '11',\n",
       " 'b']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = doc.to_semantic_network(nodes = 'words', \n",
    "                                normalize = 'lemma',\n",
    "                                edge_weighting = 'default',\n",
    "                                window_width = 10)\n",
    "\n",
    "best_coverage_nodes = textacy.keyterms.rank_nodes_by_bestcoverage(graph, \n",
    "                                                                  25,\n",
    "                                                                  c=1,\n",
    "                                                                  alpha = 1.0)\n",
    "\n",
    "list(best_coverage_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rank Nodes by Divrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     0,
     5
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usage',\n",
       " 'partition',\n",
       " '|',\n",
       " 'alphabet',\n",
       " 'important',\n",
       " 'instead',\n",
       " 'english',\n",
       " 'thus',\n",
       " 'different',\n",
       " 'if',\n",
       " 'membership',\n",
       " 'render',\n",
       " 'however',\n",
       " 'in',\n",
       " 'infinitely',\n",
       " '∉',\n",
       " 'inadequate',\n",
       " 'member',\n",
       " 'single',\n",
       " 'man',\n",
       " 'university',\n",
       " 'notion',\n",
       " 'play',\n",
       " 'separately',\n",
       " 'the',\n",
       " 'ellipsis',\n",
       " 'so',\n",
       " 'enumeration',\n",
       " 'right',\n",
       " 'define',\n",
       " 'useful',\n",
       " '4',\n",
       " 'tuple',\n",
       " 'hence',\n",
       " 'positive',\n",
       " 'georg',\n",
       " 's',\n",
       " 'respect',\n",
       " 'suit',\n",
       " 'colon',\n",
       " '6',\n",
       " '♠',\n",
       " '0',\n",
       " 'square',\n",
       " 'superset',\n",
       " 'abbreviate',\n",
       " 'every',\n",
       " 'collection',\n",
       " '♦',\n",
       " 'definition',\n",
       " 'seemingly',\n",
       " 'irrelevant',\n",
       " 'take',\n",
       " 'develop',\n",
       " 'write',\n",
       " 'property',\n",
       " 'vertical',\n",
       " 'foundation',\n",
       " '4}.',\n",
       " 'intensionally',\n",
       " 'transfiniten',\n",
       " 'call',\n",
       " 'x',\n",
       " 'choice',\n",
       " '♥',\n",
       " 'one',\n",
       " 'inclusion',\n",
       " 'age',\n",
       " 'mathematic',\n",
       " 'young',\n",
       " 'sequence',\n",
       " 'paradoxes',\n",
       " '⊃',\n",
       " 'equivalently',\n",
       " 'power',\n",
       " 'containment',\n",
       " 'differently',\n",
       " 'use',\n",
       " 'indicate',\n",
       " '∅',\n",
       " 'exactly',\n",
       " 'there',\n",
       " 'relationship',\n",
       " 'capital',\n",
       " 'number',\n",
       " 'following',\n",
       " '11',\n",
       " 'advanced',\n",
       " 'thousand',\n",
       " 'fundamental',\n",
       " 'teach',\n",
       " 'extensionality',\n",
       " 'element',\n",
       " 'identical',\n",
       " 'give',\n",
       " 'axiom',\n",
       " 'topic',\n",
       " 'n2',\n",
       " 'card',\n",
       " 'b.',\n",
       " 'belong',\n",
       " 'context',\n",
       " 'ubiquitous',\n",
       " 'equal',\n",
       " '3',\n",
       " 'bernard',\n",
       " '-PRON-',\n",
       " 'point',\n",
       " 'definite',\n",
       " 'range',\n",
       " 'notation',\n",
       " '2,4,6}.',\n",
       " 'mean',\n",
       " 'a',\n",
       " 'thought',\n",
       " 'consider',\n",
       " 'elementary',\n",
       " 'red',\n",
       " 'semantic',\n",
       " 'builder',\n",
       " 'know',\n",
       " 'y',\n",
       " 'small',\n",
       " 'b',\n",
       " 'bracket',\n",
       " 'for',\n",
       " '⊇',\n",
       " 'identity',\n",
       " 'precisely',\n",
       " 'degree',\n",
       " 'u.',\n",
       " 'concept',\n",
       " 'distinct',\n",
       " 'd',\n",
       " '19}.',\n",
       " 'flag',\n",
       " 'e',\n",
       " '∈',\n",
       " 'meaning',\n",
       " 'unlike',\n",
       " 'word',\n",
       " 'primitive',\n",
       " 'instance',\n",
       " 'german',\n",
       " 'fact',\n",
       " '19th',\n",
       " 'menge',\n",
       " 'read',\n",
       " 'example',\n",
       " 'axiomatic',\n",
       " 'extensional',\n",
       " 'red}.',\n",
       " 'blue',\n",
       " 'founder',\n",
       " 'differ',\n",
       " '⊂',\n",
       " 'moreover',\n",
       " 'work',\n",
       " \"'s\",\n",
       " 'enclose',\n",
       " 'universal',\n",
       " '9',\n",
       " 'pronounce',\n",
       " '≤',\n",
       " 'obvious',\n",
       " '2',\n",
       " 'gathering',\n",
       " 'rigor',\n",
       " 'bolzano',\n",
       " 'description',\n",
       " 'century',\n",
       " 'object',\n",
       " 'denote',\n",
       " 'way',\n",
       " 'perception',\n",
       " 'reason',\n",
       " 'expression',\n",
       " '⊆',\n",
       " 'continue',\n",
       " 'turn',\n",
       " 'integer',\n",
       " 'author',\n",
       " '−',\n",
       " 'brace',\n",
       " 'end',\n",
       " 'theory',\n",
       " 'second',\n",
       " '1',\n",
       " '8',\n",
       " 'zur',\n",
       " 'say',\n",
       " 'der',\n",
       " 'a.',\n",
       " 'anschauung',\n",
       " 'form',\n",
       " 'set',\n",
       " 'sometimes',\n",
       " 'curly',\n",
       " '1,2,3,4',\n",
       " 'bar',\n",
       " 'collectively',\n",
       " 'time',\n",
       " 'education',\n",
       " 'an',\n",
       " 'beginning',\n",
       " '12',\n",
       " 'f',\n",
       " 'color',\n",
       " 'establish',\n",
       " 'd.',\n",
       " '1000',\n",
       " 'infinite',\n",
       " 'diagram',\n",
       " 'white',\n",
       " 'green',\n",
       " 'cantor',\n",
       " 'size',\n",
       " 'derive',\n",
       " 'intensional',\n",
       " 'n',\n",
       " 'list',\n",
       " '♣',\n",
       " 'proper',\n",
       " 'multiple',\n",
       " 'subset',\n",
       " 'nearly',\n",
       " 'order',\n",
       " '⊋',\n",
       " 'specify',\n",
       " '6}.',\n",
       " 'begründung',\n",
       " 'today',\n",
       " 'general',\n",
       " 'require',\n",
       " 'extensionally',\n",
       " 'extension',\n",
       " 'perfect',\n",
       " 'technical',\n",
       " 'describe',\n",
       " 'venn',\n",
       " 'inclusive',\n",
       " 'conventionally',\n",
       " '19',\n",
       " 'french',\n",
       " 'nonempty',\n",
       " 'people',\n",
       " 'interpret',\n",
       " 'illustrate',\n",
       " 'coin',\n",
       " 'basic',\n",
       " 'beiträge',\n",
       " 'letter',\n",
       " 'include',\n",
       " 'mengenlehre',\n",
       " '⊊',\n",
       " 'c',\n",
       " 's.',\n",
       " 'contain',\n",
       " 'respectively',\n",
       " 'specification',\n",
       " 'rule',\n",
       " '=']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = doc.to_semantic_network(nodes = 'words', \n",
    "                                normalize = 'lemma',\n",
    "                                edge_weighting = 'default',\n",
    "                                window_width = 10)\n",
    "\n",
    "divrank_nodes = textacy.keyterms.rank_nodes_by_divrank(graph,\n",
    "                                                       r = None,\n",
    "                                                       lambda_ = 0.5,\n",
    "                                                       alpha = 0.5)\n",
    "\n",
    "list(divrank_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('set', 0.15232164458454564),\n",
       " ('beiträge zur begründung der', 0.0776898303734589),\n",
       " ('distinct object', 0.07598464586444324),\n",
       " ('b ⊇ a', 0.04323176012630048),\n",
       " ('mathematic', 0.03651672960335317),\n",
       " ('b ⊋ a', 0.035755240358240736),\n",
       " ('member', 0.02706716823454739),\n",
       " ('example', 0.026443713662248507),\n",
       " ('element', 0.023515408935865748),\n",
       " ('set whose member', 0.02318097873594454)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgrank_terms = textacy.keyterms.sgrank(doc,\n",
    "                                       ngrams = (1, 2, 3, 4, 5, 6),\n",
    "                                       normalize = 'lemma',\n",
    "                                       window_width = 1500,\n",
    "                                       n_keyterms = 10, \n",
    "                                       idf = None)\n",
    "\n",
    "sgrank_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SingleRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a set member', 0.17084864742825212),\n",
       " ('set b', 0.16572899424751839),\n",
       " ('definition list set member', 0.1629066576000055),\n",
       " ('a set s', 0.15368596930737224),\n",
       " ('set a', 0.1449786875444095),\n",
       " ('a set', 0.1449786875444095),\n",
       " ('set f', 0.12492888897050032),\n",
       " ('set theory', 0.12115919071334653),\n",
       " ('power set', 0.11886348104543484),\n",
       " ('set', 0.11266574048242659)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singlerank_terms = textacy.keyterms.singlerank(doc,\n",
    "                                               normalize = 'lemma',\n",
    "                                               n_keyterms = 10)\n",
    "singlerank_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('set', 0.0799725657654564),\n",
       " ('b', 0.029121585278008108),\n",
       " ('a', 0.02326949864817083),\n",
       " ('member', 0.020217515912656796),\n",
       " ('subset', 0.01575659229341563),\n",
       " ('example', 0.01518665101845617),\n",
       " ('definition', 0.014914289081537276),\n",
       " ('element', 0.014558805365359551),\n",
       " ('number', 0.013241001115891474),\n",
       " ('f', 0.01311706956666036)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank_terms = textacy.keyterms.textrank(doc,\n",
    "                                           normalize = 'lemma',\n",
    "                                           n_keyterms = 10)\n",
    "\n",
    "textrank_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Vectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GroupVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer_grp = textacy.vsm.vectorizers.GroupVectorizer(tf_type = 'linear',\n",
    "                                                     apply_idf = True,\n",
    "                                                     idf_type = 'smooth',\n",
    "                                                     apply_dl = False,\n",
    "                                                     dl_type = 'linear',\n",
    "                                                     norm = None,\n",
    "                                                     min_df = 1,\n",
    "                                                     max_df = 1.0,\n",
    "                                                     max_n_terms = None,\n",
    "                                                     vocabulary_terms = None,\n",
    "                                                     vocabulary_grps = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = textacy.vsm.vectorizers.Vectorizer(tf_type = 'linear',\n",
    "                                                apply_idf = False,\n",
    "                                                idf_type = 'smooth',\n",
    "                                                apply_dl = False,\n",
    "                                                dl_type = 'sqrt',\n",
    "                                                norm = None,\n",
    "                                                min_df = 1,\n",
    "                                                max_df = 1.0,\n",
    "                                                max_n_terms = None,\n",
    "                                                vocabulary_terms = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.85714280605316,
   "position": {
    "height": "387px",
    "left": "439.4021911621094px",
    "right": "152.9891357421875px",
    "top": "85.99185180664063px",
    "width": "565px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
